
class Section(BaseModel):
    section_title: str = Field(default=None, description="Title of the Section")
    section_content: str = Field(default=None, description="Brief overview of concept to be covered in this section.")


class sections(BaseModel):
    sections: List[Section] = Field(default=None, description="List of sections for the course outline.")


class State(TypedDict):
    topic: str
    final_report: str
    sections: List[Section]
    completed_sections: Annotated[list, operator.add]
    each_section: Section  # Add this field


# Initialize the LLM (you need to configure this)
llm = AzureChatOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version="2024-02-15-preview",
    deployment_name="your-deployment-name"
)

planner_llm = llm.with_structured_output(sections)


def generate_outline(state: State):
    outline = planner_llm.invoke(
        f"Generate optimal sections for a report on topic: {state['topic']}. "
        "Please follow report format with introduction, body and conclusion, references etc."
    )
    return {'sections': outline.sections}


def write_report(state: State):
    # Access the section from state
    each_section = state['each_section']
    
    messages = [
        SystemMessage(content=f"Please write a section for the report topic: {state['topic']} "
                              "for the provided title and description. Please do not include preamble "
                              "and use markdown formatting for the report."),
        HumanMessage(content=f"Here is the title of Section: {each_section.section_title} "
                             f"and the description for the Section: {each_section.section_content}. "
                             "Please create the full section")
    ]
    
    report = llm.invoke(messages)
    
    return {'completed_sections': [report.content]}


def synthesizer(state: State):
    """Synthesize full report from sections"""
    
    # List of completed sections
    completed_sections = state["completed_sections"]
    
    # Format completed section to str to use as context for final sections
    completed_report_sections = "\n\n---\n\n".join(completed_sections)
    
    return {"final_report": completed_report_sections}


from langgraph.types import Send


# Conditional edge function to create llm_call workers that each write a section of the report
def assign_workers(state: State):
    """Assign a worker to each section in the plan"""
    
    # Kick off section writing in parallel via Send() API
    return [Send("write_report", {"each_section": s, "topic": state["topic"]}) for s in state["sections"]]


workflow = StateGraph(State)
workflow.add_node("outline_node", generate_outline)
workflow.add_node("write_report", write_report)
workflow.add_node("synthesizer", synthesizer)

workflow.add_edge(START, "outline_node")
workflow.add_conditional_edges(
    "outline_node", assign_workers, ["write_report"]
)
workflow.add_edge("write_report", "synthesizer")
workflow.add_edge("synthesizer", END)

chain = workflow.compile()
result = chain.invoke({"topic": "digital fraud"})

print(result["final_report"])